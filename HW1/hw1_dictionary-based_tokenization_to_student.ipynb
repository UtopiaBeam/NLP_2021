{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"colab":{"name":"hw1_dictionary-based_tokenization_to_student.ipynb","provenance":[{"file_id":"1vB0n4NP0BRVPueJB1ICQt_uTvZclaXDz","timestamp":1611031917371},{"file_id":"1VBE3DFY6pZEk-sR2kuuq7VYqjfI7pDgV","timestamp":1610628767964}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"7EdbVSmE87En"},"source":["# HW1: Dictionary-based Tokenization \n"]},{"cell_type":"markdown","metadata":{"id":"pJJLm1Ub87Et"},"source":["In this exercise, you are to implement a dictionary-based word segmentation algorithm. There are two Python functions that you need to complete: \n","<br>\n","* maximal_matching\n","* backtrack\n","</br>\n","\n","Also, you have to find how to use word_tokenize() in PythaiNLP along with customer_dict by yourselves."]},{"cell_type":"markdown","metadata":{"id":"DF5Pme7CK3YF"},"source":["## Part1) Your Maximal Matching with Your Dictionary"]},{"cell_type":"markdown","metadata":{"id":"xzs0R06q87Et"},"source":["### Create a toy dictionary to test the algorithm\n","\n","This is based on the example shown in the lecture. \n","You will tokenize the following text string: \"ไปหามเหสี!\"\n","The toy dictoionary provided in this exercise includes all the charaters, syllables, and words that appear that the text string."]},{"cell_type":"code","metadata":{"id":"pq3W4p3z87Ev","executionInfo":{"status":"ok","timestamp":1611210261425,"user_tz":-420,"elapsed":7844,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}}},"source":["thai_vocab = [\"ไ\",\"ป\",\"ห\",\"า\",\"ม\",\"เ\",\"ห\",\"ส\",\"ี\",\"ไป\",\"หา\",\"หาม\",\"เห\",\"สี\",\"มเหสี\",\"!\"]"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZornooGF87Ew"},"source":["### Maximal matching \n","Complete the maximal matching  function below to tokenize the input text\n"]},{"cell_type":"code","metadata":{"id":"Ao4d2E3387Ew","executionInfo":{"status":"ok","timestamp":1611210261426,"user_tz":-420,"elapsed":7833,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}}},"source":["from math import inf #infinity\n","def maximal_matching(c):\n","    #Initialize an empty 2D list\n","    d = [[None]*len(c) for _ in range(len(c))]\n","    \n","    ####FILL CODE HERE####\n","\n","    for i in range(len(c)):\n","      for j in range(i, len(c)):\n","        if i == 0 and c[0:j+1] in thai_vocab:\n","          d[i][j] = 1\n","        elif c[i:j+1] in thai_vocab:\n","          d[i][j] = inf\n","          for k in range(i):\n","            d[i][j] = min(d[i][j], 1 + d[k][i-1])\n","        else:\n","          d[i][j] = inf\n","\n","    ######################\n","    \n","    return d"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w7vBXfjM87Ew"},"source":["### Backtracking\n","Complete the backtracking function below to find the tokenzied words.\n","It should return a list containing a pair of the beginning position and the ending position of each word.\n","In this example, it should return: \n","<br>\n","[(0, 1),(2, 3),(4, 8),(9, 9)]\n","<br> \n","#### Each pair contains the position of each word as follows:\n","(0, 1) ไป\n","<br>\n","(2, 3) หา\n","<br>\n","(4, 8) มเหสี\n","<br>\n","(9, 9) !\n"]},{"cell_type":"code","metadata":{"id":"SxNFf1IE87Ex","executionInfo":{"status":"ok","timestamp":1611210261426,"user_tz":-420,"elapsed":7829,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}}},"source":["def backtrack(d):\n","    eow = len(d)-1 # End of Word position\n","    word_pos = [] # Word position\n","    ####FILL CODE HERE####\n","    \n","    while eow >= 0:\n","      min_word_count = inf\n","      sow = -1  # start of word\n","\n","      for i in range(eow, -1, -1):\n","        if d[i][eow] == None:\n","          break\n","        if d[i][eow] < min_word_count:\n","          sow = i\n","          min_word_count = d[i][eow]\n","      \n","      word_pos.append((sow, eow))\n","      eow = sow - 1\n","\n","    ######################\n","    word_pos.reverse()\n","    return word_pos\n"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q0MJkKsh87Ex"},"source":["### Test your maximal matching algorithm on a toy dictionary\n","\n","Expected output:\n","\n","[1, 1, inf, inf, inf, inf, inf, inf, inf, inf] ไ\n","<br>\n","[None, 2, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","<br>\n","[None, None, 2, 2, 2, inf, inf, inf, inf, inf] ห\n","<br>\n","[None, None, None, 3, inf, inf, inf, inf, inf, inf] า\n","<br>\n","[None, None, None, None, 3, inf, inf, inf, 3, inf] ม\n","<br>\n","[None, None, None, None, None, 3, 3, inf, inf, inf] เ\n","<br>\n","[None, None, None, None, None, None, 4, inf, inf, inf] ห\n","<br>\n","[None, None, None, None, None, None, None, 4, 4, inf] ส\n","<br>\n","[None, None, None, None, None, None, None, None, 5, inf] ี\n","<br>\n","[None, None, None, None, None, None, None, None, None, 4] !\n","<br>"]},{"cell_type":"code","metadata":{"id":"tsmVQIKS87Ey","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611210261427,"user_tz":-420,"elapsed":7827,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}},"outputId":"347a324d-999e-4468-dfbc-34cc73844563"},"source":["input_text = \"ไปหามเหสี!\"\n","out = maximal_matching(input_text)\n","for i in range(len(out)):\n","    print(out[i],input_text[i])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["[1, 1, inf, inf, inf, inf, inf, inf, inf, inf] ไ\n","[None, 2, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","[None, None, 2, 2, 2, inf, inf, inf, inf, inf] ห\n","[None, None, None, 3, inf, inf, inf, inf, inf, inf] า\n","[None, None, None, None, 3, inf, inf, inf, 3, inf] ม\n","[None, None, None, None, None, 3, 3, inf, inf, inf] เ\n","[None, None, None, None, None, None, 4, inf, inf, inf] ห\n","[None, None, None, None, None, None, None, 4, 4, inf] ส\n","[None, None, None, None, None, None, None, None, 5, inf] ี\n","[None, None, None, None, None, None, None, None, None, 4] !\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IVhCMM4d87Ey"},"source":["### Test your backtracking algorithm on a toy dictionary\n","Expected output:\n","<br>\n","ไป|หา|มเหสี|!"]},{"cell_type":"code","metadata":{"id":"6Hurbm1f87Ey","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611210261427,"user_tz":-420,"elapsed":7823,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}},"outputId":"f7c4ed2e-73c9-4543-f4cb-51117e1ea990"},"source":["def print_tokenized_text(d, input_text):\n","    tokenized_text=[]\n","    for pos in backtrack(d):\n","        #print(pos)\n","        tokenized_text.append(input_text[pos[0]:pos[1]+1])\n","\n","    print(\"|\".join(tokenized_text))\n","    \n","print_tokenized_text(out,input_text)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["ไป|หา|มเหสี|!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"57rP9cTU87Ez"},"source":["## Part2) Your Maximal Matching with Real Dictionary"]},{"cell_type":"markdown","metadata":{"id":"V306h7AG87Ez"},"source":["For UNIX-based OS users, the following cell will download a dictionary (it's just a list of thai words). Alternatively, you can download it from this link: https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"EFVR9LO187Ez","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611210262800,"user_tz":-420,"elapsed":9192,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}},"outputId":"49b22dfd-5822-474f-9422-d5479e6aeaa6"},"source":["!wget https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt"],"execution_count":18,"outputs":[{"output_type":"stream","text":["--2021-01-21 06:24:21--  https://raw.githubusercontent.com/PyThaiNLP/pythainlp/dev/pythainlp/corpus/words_th.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1521600 (1.5M) [text/plain]\n","Saving to: ‘words_th.txt.1’\n","\n","words_th.txt.1      100%[===================>]   1.45M  --.-KB/s    in 0.09s   \n","\n","2021-01-21 06:24:21 (15.9 MB/s) - ‘words_th.txt.1’ saved [1521600/1521600]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nqIQzVgE87E0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611210262800,"user_tz":-420,"elapsed":9188,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}},"outputId":"ef8a9d89-9381-48d6-d8d5-98cb680c1ba3"},"source":["with open(\"words_th.txt\",encoding='utf-8-sig') as f:\n","    thai_vocab = f.read().splitlines() \n","print(\"Vocab size:\", len(thai_vocab))\n","print(thai_vocab[:10])\n","\n","thai_vocab.extend([\"ๆ\",\"!\"])"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Vocab size: 62143\n","['ก ข ไม่กระดิกหู', 'ก.', 'ก.ค.', 'ก.ต.', 'ก.ป.ส.', 'ก.พ.', 'ก.พ.ด.', 'ก.ม.', 'ก.ย.', 'ก.ย']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kpjwzw1w87E0"},"source":["### The output of your maximal matching algoithm on a new dictionary\n","Expected output:\n","<br>\n","[1, 1, 100000, 1, 100000, 100000, 100000, 100000, 100000] ไ\n","<br>\n","[None, 2, 100000, 100000, 100000, 100000, 100000, 100000, 100000] ป\n","<br>\n","[None, None, 2, 2, 2, 100000, 100000, 100000, 100000] ห\n","<br>\n","[None, None, None, 100000, 100000, 100000, 100000, 100000, 100000] า\n","<br>\n","[None, None, None, None, 2, 100000, 100000, 100000, 2] ม\n","<br>\n","[None, None, None, None, None, 100000, 3, 100000, 100000] เ\n","<br>\n","[None, None, None, None, None, None, 100001, 100000, 100000] ห\n","<br>\n","[None, None, None, None, None, None, None, 4, 4] ส\n","<br>\n","[None, None, None, None, None, None, None, None, None] ี"]},{"cell_type":"code","metadata":{"id":"lYD5ChIS87E0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611210262801,"user_tz":-420,"elapsed":9184,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}},"outputId":"b1000de7-b671-4690-a078-057724635f18"},"source":["input_text = \"ไปหามเหสี\"\n","out = maximal_matching(input_text)\n","for i in range(len(out)):\n","    print(out[i],input_text[i])"],"execution_count":20,"outputs":[{"output_type":"stream","text":["[inf, 1, inf, 1, inf, inf, inf, inf, inf] ไ\n","[None, inf, inf, inf, inf, inf, inf, inf, inf] ป\n","[None, None, inf, 2, 2, inf, inf, inf, inf] ห\n","[None, None, None, inf, inf, inf, inf, inf, inf] า\n","[None, None, None, None, inf, inf, inf, inf, 2] ม\n","[None, None, None, None, None, inf, 3, inf, inf] เ\n","[None, None, None, None, None, None, inf, inf, inf] ห\n","[None, None, None, None, None, None, None, inf, 4] ส\n","[None, None, None, None, None, None, None, None, inf] ี\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BSqLuK7G87E0"},"source":["### Expected tokenized text\n","ไปหา|มเหสี"]},{"cell_type":"code","metadata":{"id":"TI077jmy87E0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611210262801,"user_tz":-420,"elapsed":9180,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}},"outputId":"a526b49b-af97-4641-eb65-79d1dd6d921c"},"source":["# print('ไปหา' in thai_vocab)\n","# print('มเหสี' in thai_vocab)\n","# print('ปปป' in thai_vocab)\n","print_tokenized_text(out,input_text)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["ไปหา|มเหสี\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VLGgO8PrLSz6"},"source":["## Part3) Maximal Matching from PythaiNLP"]},{"cell_type":"markdown","metadata":{"id":"LrZrzQoXLeUX"},"source":["### Default dictionary\n","\n","Study word_tokenize() from PythaiNLP in the link below.\n","\n","https://thainlp.org/pythainlp/docs/2.0/api/tokenize.html"]},{"cell_type":"code","metadata":{"id":"yXxPBOcNLXfm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611210259314,"user_tz":-420,"elapsed":30258,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}},"outputId":"f7df0b98-91d7-4717-bb86-b155e836b031"},"source":["!pip install pythainlp\n","!pip install marisa_trie"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Collecting pythainlp\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/09/1215cb6f6ef0cfc9dbb427a961fda8a47c111955f782f659ca2d38c79adc/pythainlp-2.2.6-py3-none-any.whl (10.6MB)\n","\u001b[K     |████████████████████████████████| 10.6MB 4.0MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (2.23.0)\n","Collecting python-crfsuite>=0.9.6\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n","\u001b[K     |████████████████████████████████| 747kB 49.9MB/s \n","\u001b[?25hCollecting tinydb>=3.0\n","  Downloading https://files.pythonhosted.org/packages/e5/7e/85ee672ee60affd5b4461efa19f260cf7575f36b94fbd1f0825742639910/tinydb-4.3.0-py3-none-any.whl\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2.10)\n","Installing collected packages: python-crfsuite, tinydb, pythainlp\n","Successfully installed pythainlp-2.2.6 python-crfsuite-0.9.7 tinydb-4.3.0\n","Collecting marisa_trie\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/95/d23071d0992dabcb61c948fb118a90683193befc88c23e745b050a29e7db/marisa-trie-0.7.5.tar.gz (270kB)\n","\u001b[K     |████████████████████████████████| 276kB 5.5MB/s \n","\u001b[?25hBuilding wheels for collected packages: marisa-trie\n","  Building wheel for marisa-trie (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for marisa-trie: filename=marisa_trie-0.7.5-cp36-cp36m-linux_x86_64.whl size=862296 sha256=46b67adf6f63ded5725cc2e537c95450bb0010bfed2ae5a6a6ef5780731e0e52\n","  Stored in directory: /root/.cache/pip/wheels/45/24/79/022624fc914f0e559fe8a1141aaff1f9df810905a13fc75d57\n","Successfully built marisa-trie\n","Installing collected packages: marisa-trie\n","Successfully installed marisa-trie-0.7.5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"goQE5gFUL4KO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611210261422,"user_tz":-420,"elapsed":32361,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}},"outputId":"4b6a8b56-9d16-4c51-c58b-207c80193054"},"source":["from pythainlp.tokenize import word_tokenize\n","text='นัดกินกันตอนไหนก็ได้ที่สามย่านมิตรทาวน์'\n","\n","####FILL CODE HERE####\n","word_tokenize(text)\n","######################"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่าน', 'มิตร', 'ทาวน์']"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"2SlX5cEBMHPd"},"source":["### Custom dictionary\n","\n","Add 'สามย่านมิตรทาวน์' into dictionary and then tokenize again"]},{"cell_type":"code","metadata":{"id":"b4V9TqFaMPAj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1611210261422,"user_tz":-420,"elapsed":32355,"user":{"displayName":"Natchapol Srisang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhjWg6rOQzf-NhtIDhRMxRM03pGf-8OVvx7m2byMw=s64","userId":"16322571578720413111"}},"outputId":"0fdaa95e-bf20-4dee-822b-0f4fc4d8cb1a"},"source":["####FILL CODE HERE####\n","from marisa_trie import Trie\n","\n","trie = Trie(thai_vocab + ['สามย่านมิตรทาวน์'])\n","word_tokenize(text, trie)\n","######################"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['นัด', 'กินกัน', 'ตอน', 'ไหน', 'ก็', 'ได้ที่', 'สามย่านมิตรทาวน์']"]},"metadata":{"tags":[]},"execution_count":12}]}]}